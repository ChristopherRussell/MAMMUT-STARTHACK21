{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.cbook import get_sample_data\n",
    "import matplotlib.animation as animation\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_from_start(end_time):\n",
    "    t_step = end_time.replace(tzinfo=None)  - moves_df.start_time[0].replace(tzinfo=None) \n",
    "    frame_number = t_step.total_seconds()\n",
    "    return frame_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_rectangle(src, top_left, bottom_right, radius=1, color=255, thickness=1, line_type=cv2.LINE_AA):\n",
    "\n",
    "    #  corners:\n",
    "    #  p1 - p2\n",
    "    #  |     |\n",
    "    #  p4 - p3\n",
    "\n",
    "    p1 = top_left\n",
    "    p2 = (bottom_right[1], top_left[1])\n",
    "    p3 = (bottom_right[1], bottom_right[0])\n",
    "    p4 = (top_left[0], bottom_right[0])\n",
    "\n",
    "    height = abs(bottom_right[0] - top_left[1])\n",
    "\n",
    "    if radius > 1:\n",
    "        radius = 1\n",
    "\n",
    "    corner_radius = int(radius * (height/2))\n",
    "\n",
    "    if thickness < 0:\n",
    "\n",
    "        #big rect\n",
    "        top_left_main_rect = (int(p1[0] + corner_radius), int(p1[1]))\n",
    "        bottom_right_main_rect = (int(p3[0] - corner_radius), int(p3[1]))\n",
    "\n",
    "        top_left_rect_left = (p1[0], p1[1] + corner_radius)\n",
    "        bottom_right_rect_left = (p4[0] + corner_radius, p4[1] - corner_radius)\n",
    "\n",
    "        top_left_rect_right = (p2[0] - corner_radius, p2[1] + corner_radius)\n",
    "        bottom_right_rect_right = (p3[0], p3[1] - corner_radius)\n",
    "\n",
    "        all_rects = [\n",
    "        [top_left_main_rect, bottom_right_main_rect], \n",
    "        [top_left_rect_left, bottom_right_rect_left], \n",
    "        [top_left_rect_right, bottom_right_rect_right]]\n",
    "\n",
    "        [cv2.rectangle(src, rect[0], rect[1], color, thickness) for rect in all_rects]\n",
    "\n",
    "    # draw straight lines\n",
    "    cv2.line(src, (p1[0] + corner_radius, p1[1]), (p2[0] - corner_radius, p2[1]), color, abs(thickness), line_type)\n",
    "    cv2.line(src, (p2[0], p2[1] + corner_radius), (p3[0], p3[1] - corner_radius), color, abs(thickness), line_type)\n",
    "    cv2.line(src, (p3[0] - corner_radius, p4[1]), (p4[0] + corner_radius, p3[1]), color, abs(thickness), line_type)\n",
    "    cv2.line(src, (p4[0], p4[1] - corner_radius), (p1[0], p1[1] + corner_radius), color, abs(thickness), line_type)\n",
    "\n",
    "    # draw arcs\n",
    "    cv2.ellipse(src, (p1[0] + corner_radius, p1[1] + corner_radius), (corner_radius, corner_radius), 180.0, 0, 90, color ,thickness, line_type)\n",
    "    cv2.ellipse(src, (p2[0] - corner_radius, p2[1] + corner_radius), (corner_radius, corner_radius), 270.0, 0, 90, color , thickness, line_type)\n",
    "    cv2.ellipse(src, (p3[0] - corner_radius, p3[1] - corner_radius), (corner_radius, corner_radius), 0.0, 0, 90,   color , thickness, line_type)\n",
    "    cv2.ellipse(src, (p4[0] + corner_radius, p4[1] - corner_radius), (corner_radius, corner_radius), 90.0, 0, 90,  color , thickness, line_type)\n",
    "\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Video and stats\n",
    "cap = cv2.VideoCapture('./data/overhang/Overhang.mp4')\n",
    "ret, frame = cap.read()\n",
    "cv2.imshow('frame', frame)\n",
    "fps = cap.get(cv2.cv2.CAP_PROP_FPS)\n",
    "width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess moves data corresponding to video\n",
    "moves_df = pd.read_csv(\"./data/overhang/overhang_moves.csv\")\n",
    "moves_df[['start_time', 'end_time']] = moves_df[['start_time', 'end_time']].apply(pd.to_datetime)\n",
    "moves_df['time_from_start'] = moves_df['end_time'].apply(time_from_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess moves data corresponding to video\n",
    "h5_file_name = './data/overhang/overhang.h5'\n",
    "f = h5py.File(h5_file_name, 'r')\n",
    "height_profile = f['climbs/0/height_profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addStats(time, frame):\n",
    "    query_df = moves_df[moves_df['time_from_start'] <= time]\n",
    "    if query_df.shape[0] != 0:\n",
    "        cv2.putText(frame, \"Total Moves {}\".format(query_df.move_index.max()),\n",
    "                                                   (10, 20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                                   0.5, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.putText(frame, \"Total time on hold:\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    left_hold = query_df[query_df['hand'] == 'left']\n",
    "    right_hold = query_df[query_df['hand'] == 'right']\n",
    "    if left_hold.shape[0] != 0 and right_hold.shape[0] != 0:\n",
    "        cv2.putText(frame, f\"L: {round(left_hold.on_hold.sum(), 2)} seconds\",\n",
    "                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, f\"R: {round(right_hold.on_hold.sum(), 2)} seconds\",\n",
    "                    (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-2dae65360949>, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-2dae65360949>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    plt.plot(x, y, linewidth=7.0, alpha=0.5. color=\"purple\")\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "h5_file_name = './data/overhang/overhang.h5'\n",
    "f = h5py.File(h5_file_name, 'r')\n",
    "height_profile = f['climbs/0/height_profile']\n",
    "max_height = max(height_profile)\n",
    "max_height_index = np.argmax(height_profile, axis=0)\n",
    "len_height = len(height_profile)\n",
    "rocket = Image.open('../rocket.png')\n",
    "rocket = rocket.resize((50,50))\n",
    "\n",
    "def imscatter(x, y, image, ax=None, zoom=1):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    try:\n",
    "        image = plt.imread(image)\n",
    "    except TypeError:\n",
    "        # Likely already an array...\n",
    "        pass\n",
    "    im = OffsetImage(image, zoom=zoom)\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    for x0, y0 in zip(x, y):\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists\n",
    "\n",
    "def rocketGraphFunc(time, frame, add_rocket):\n",
    "    if time > len_height / 10:\n",
    "        time = len_height / 10\n",
    "    plt.clf()\n",
    "    ## for '/climbs/0/height_profile' we are sampling at 10Hz, i.e. every 0.1s\n",
    "    #ind = min(math.floor(time/0.1), len_height - 1) # stay in bounds\n",
    "\n",
    "    nr_readings = min(math.floor(time/0.1), max_height_index - 1)\n",
    "    if nr_readings == 0:\n",
    "        return frame\n",
    "    \n",
    "    x = range(nr_readings)\n",
    "    y = height_profile[:nr_readings]\n",
    "    plt.plot(x, y, linewidth=7.0, alpha=0.5, color=\"purple\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    if add_rocket:\n",
    "        imscatter([max_height_index], [max_height],\n",
    "                  '../moon.png', zoom=0.1, ax=ax)\n",
    "        imscatter([nr_readings], [height_profile[nr_readings - 1]],\n",
    "                  '../rocket.png', zoom=0.1, ax=ax)\n",
    "    plt.ylim(0,max_height)\n",
    "    plt.xlim(0,len_height)\n",
    "\n",
    "    ax.annotate(xy=(x[-1], y[-1]), xytext=(25,0), textcoords='offset points',\n",
    "                text=str(\"{:.1f}\".format(y[-1]))+'m', va='center', size=14)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "    fig_width = frame.shape[0] / 80\n",
    "    fig_height = frame.shape[1] / 80\n",
    "\n",
    "    plt.gcf().set_size_inches(fig_height, fig_width)\n",
    "\n",
    "    plt.savefig('over_plot.png', transparent=True, dpi=80)\n",
    "\n",
    "    # imread_unchange reads plot.png with 4 channels, i.e. including alpha channel which\n",
    "    # describes the transparancy\n",
    "    overlay = cv2.imread('over_plot.png', cv2.IMREAD_UNCHANGED)\n",
    "    new_frame = frame\n",
    "\n",
    "    y_offset = x_offset = 0\n",
    "    y1, y2 = y_offset, y_offset + overlay.shape[0]\n",
    "    x1, x2 = x_offset, x_offset + overlay.shape[1]\n",
    "    alpha_o = overlay[:, :, 3] / 255.0\n",
    "    alpha_n = 1.0 - alpha_o\n",
    "    for c in range(0, 3):\n",
    "        new_frame[y1:y2, x1:x2, c] = (alpha_o * overlay[:, :, c] +\n",
    "                                  alpha_n * new_frame[y1:y2, x1:x2, c])\n",
    "\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playback speed = out_fps/30 * speed_up   \n",
    "# speed_up is positive int, e.g. 2 means skip every 2nd frame, 3 skip every 3rd frame\n",
    "# start_time is the time to start plotting\n",
    "def overlayGraph(infile, outfile, start_time, end_time, out_fps, speed_up):\n",
    "    cap = cv2.VideoCapture(infile)\n",
    "    writer = cv2.VideoWriter(outfile, cv2.VideoWriter_fourcc(*'MP4V'), out_fps, (width, height))    \n",
    "\n",
    "    # Set figure size, so it's not bigger than video\n",
    "    frame_count = 0 # count which frame we are on\n",
    "\n",
    "    # attributes of rectangle for overlay data\n",
    "    top_left = (0, 0)\n",
    "    bottom_right = (100, 200)\n",
    "    color = (153, 153, 153)\n",
    "    \n",
    "    while True:\n",
    "        if not (frame_count % speed_up == 0):\n",
    "            cap.read()\n",
    "            frame_count += 1\n",
    "            continue\n",
    "        ret, frame = cap.read()\n",
    "        # original video has 30fps, so divide frames by 30 to get current time\n",
    "        time = frame_count / fps;\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # we edit frame to overlay a graph. graphFunc could be replaced by\n",
    "        # another function to modify frames\n",
    "        if start_time < time:\n",
    "            frame = rounded_rectangle(frame, top_left, bottom_right, color=color, radius=0.5, thickness=-1)\n",
    "            data_time = time - start_time\n",
    "            \n",
    "#             figure(num=None, figsize=(width/80, height/80), dpi=80)\n",
    "            frame = rocketGraphFunc(data_time, frame, True) # True to add rocket  \n",
    "            \n",
    "            addStats(data_time, frame) # add move statistics and hold times\n",
    "            \n",
    "            handPlot(data_time, frame, True) # add hand acceleration magnitude graphic\n",
    "            handPlot(data_time, frame, False) # add hand acceleration magnitude graphic\n",
    "\n",
    "        writer.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "max_height = max(height_profile)\n",
    "len_height = len(height_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/overhang/overhang.csv', header = None)\n",
    "arr = pd.DataFrame(data).to_numpy()\n",
    "absVec = (arr[:,1]**2+arr[:,2]**2+arr[:,3]**2)**(0.5)\n",
    "absVec2 = (arr[:,4]**2+arr[:,5]**2+arr[:,6]**2)**(0.5)\n",
    "nof = len(absVec)\n",
    "\n",
    "redDot, = plt.plot([0], [np.sin(0)], 'ro')\n",
    "hand = Image.open('handp.png')\n",
    "siz = 75\n",
    "\n",
    "def handPlot(time, frame, left_or_right):\n",
    "    if time > nof / 50:\n",
    "        time = nof / 50\n",
    "    pos = math.floor(time * 50)\n",
    "    if pos == 0:\n",
    "        return frame\n",
    "    \n",
    "    hand_ = hand.resize((siz,siz))\n",
    "    plt.clf()\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    plt.plot([0],[0])\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    redDot.set_data(pos, pos)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if left_or_right:\n",
    "        hand_data = absVec\n",
    "    else:\n",
    "        hand_data = absVec2\n",
    "        \n",
    "    fig_width = frame.shape[1] / 80 / 4\n",
    "    fig_height = frame.shape[0] / 80 / 4\n",
    "    fig.set_size_inches(fig_width, fig_height)\n",
    "    fig.figimage(hand.resize((math.floor(siz*hand_data[pos]),math.floor(siz*hand_data[pos]))),\n",
    "                              xo=(fig_width * 80 / 2)-math.floor(siz*hand_data[pos]/2),\n",
    "                              yo=(fig_height * 80 / 2)-math.floor(siz*hand_data[pos]/2),\n",
    "                              alpha=0.5+(0.2*hand_data[pos]),\n",
    "                              cmap=plt.gray())\n",
    "    \n",
    "    plt.savefig('over_hand_plot.png', transparent=True, dpi=80)\n",
    "\n",
    "    overlay = cv2.imread('over_hand_plot.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    new_frame = frame\n",
    "\n",
    "    if left_or_right:\n",
    "        x_offset = int(2 * frame.shape[1] / 4)\n",
    "    else:\n",
    "        x_offset = int(3 * frame.shape[1] / 4)\n",
    "\n",
    "    y_offset = int(3 * frame.shape[0] / 4)\n",
    "    y1, y2 = y_offset, y_offset + overlay.shape[0]\n",
    "    x1, x2 = x_offset, x_offset + overlay.shape[1]\n",
    "    alpha_o = overlay[:, :, 3] / 255.0\n",
    "    alpha_n = 1.0 - alpha_o\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        new_frame[y1:y2, x1:x2, c] = (alpha_o * overlay[:, :, c] +\n",
    "                                  alpha_n * new_frame[y1:y2, x1:x2, c])\n",
    "\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 81x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overlayGraph('./data/overhang/Overhang.mp4', 'overhang_overlay.mp4', 8, 10000, 30, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
