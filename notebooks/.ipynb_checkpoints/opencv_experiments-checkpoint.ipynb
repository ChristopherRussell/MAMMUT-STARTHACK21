{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indian-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import math\n",
    "import matplotlib.animation as ani\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acoustic-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphFunc(time, frame, height_profile):\n",
    "    max_height = max(height_profile)\n",
    "    len_height = len(height_profile)\n",
    "    \n",
    "    if time > len_height:\n",
    "        return True\n",
    "    plt.clf()\n",
    "    # for '/climbs/0/height_profile' we are sampling at 10Hz, i.e. every 0.1s\n",
    "    ind = min(math.floor(time/0.1), len_height) # stay in bounds\n",
    "    plt.plot(height_profile[:math.floor(time/0.1)], linewidth=7.0, alpha=0.5)\n",
    "    plt.ylim(0,max_height)\n",
    "    plt.xlim(0,len_height)\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    \n",
    "    plt.savefig('plot.png', transparent=True)\n",
    "\n",
    "    # imread_unchange reads plot.png with 4 channels, i.e. including alpha channel which\n",
    "    # describes the transparancy\n",
    "    overlay = cv2.imread('plot.png', cv2.IMREAD_UNCHANGED)\n",
    "    new_frame = frame\n",
    "\n",
    "    y_offset = x_offset = 5\n",
    "    y1, y2 = y_offset, y_offset + overlay.shape[0]\n",
    "    x1, x2 = x_offset, x_offset + overlay.shape[1]\n",
    "    alpha_o = overlay[:, :, 3] / 255.0\n",
    "    alpha_n = 1.0 - alpha_o\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        new_frame[y1:y2, x1:x2, c] = (alpha_o * overlay[:, :, c] +\n",
    "                                  alpha_n * new_frame[y1:y2, x1:x2, c])\n",
    "    \n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increased-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playback speed = out_fps/30 * speed_up   \n",
    "# speed_up is positive int, e.g. 2 means skip every 2nd frame, 3 skip every 3rd frame\n",
    "def overlayGraph(videofile, h5_file, outfile, graphFunc, out_fps, speed_up):\n",
    "    f = h5py.File(h5_file_name, 'r')\n",
    "    height_profile = f['climbs/0/height_profile']\n",
    "    \n",
    "    cap = cv2.VideoCapture(videofile)\n",
    "    \n",
    "    width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    writer= cv2.VideoWriter(outfile, cv2.VideoWriter_fourcc(*'MP4V'), out_fps, (width,height))    \n",
    "\n",
    "    \"\"\" Set figure size, so it's not bigger than video \"\"\"\n",
    "    figure(num=None, figsize=((width - 20)/80, (height - 20)/80), dpi=80)\n",
    "    i = 0 # count which frame we are on\n",
    "    while True:\n",
    "        if not (i % speed_up == 0):\n",
    "            cap.read()\n",
    "            i+=1\n",
    "            continue\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        time = i / 30;\n",
    "        new_frame = graphFunc(time, frame, height_profile)\n",
    "\n",
    "        writer.write(new_frame)\n",
    "        cv2.imshow('frame', new_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "            \n",
    "        i+=1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entire-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_name = '../data/overhang/bae8f52c-407e-5f89-a8e3-61fcca51ee0a.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "leading-weather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS0AAAHqCAYAAABRDhjiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAxOAAAMTgF/d4wjAAANE0lEQVR4nO3c76uneV3H8dfbPbqjjh5XTXft7LriqhsWayjVDQtjhbAbEUqUIYREbUElDN4o6Q/IGy4hEexiILR3ChW9I4iFYiTGpmhGbesmup7wBxVaU62yu59uzIzujuPs6PeaPee183jAF+Zc1/X9fD63nnyu61xnZq0VgBZPOuoFAHw/RAuoIlpAFdECqogWUEW0gCqiBVTZO6qJb7755nXPPfcc1fTA8TUXO3lkO63Tp08f1dRAMbeHQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQJVLitbMvHNmvjAza2ZecfbYiZl5/8zcOzOfmZkPz8xNl3W1wBXvUnda70ny6iRfPO/4nUletta6JckHkrxrw7UBfJdLitZa62NrrcPzjj2w1vrgWmudPfSJJDduvD6AR9nymdZbcma3BXDZ7G0xyMy8LclNSW69yDWnkpw69/P+/v4WUwNXmJ13WjPz1iSvT/K6tdb/fq/r1lq3r7UOzn1Onjy569TAFWinndbZ3dMbk7x2rfX1TVYEcBGX+srDHTNzmOQgyYdm5r6ZOUjyjiTPSvKRmfn0zPzd5VsqwCXutNZat32PU7PhWgAekzfigSqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaDKJUVrZt45M1+YmTUzr3jE8ZfMzMdn5t6ZuXtmXn7ZVgqQS99pvSfJq5N88bzjdyS5c6310iRvT/Lu7ZYG8N0uKVprrY+ttQ4feWxmnpfkVUnuOnvovUmun5mbtl0iwHfs8kzr+iRfXms9mCRrrZXk/iQ3bLEwgAt53B7Ez8ypmTk89zl9+vTjNTXwBLJLtL6U5LqZ2UuSmZmc2WXdf6GL11q3r7UOzn1Onjy5w9TAleoHjtZa62tJPpXkTWcPvSHJ4Vrrvi0WBnAhl/rKwx0zc5jkIMmHZuZcmG5LctvM3Jvk95O8+fIsE+CMOfP8/PF3cHCwDg8PH/tC4EozFzvpjXigimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVTaJ1sz8/Mx8amY+PTP/ODO/tsW4AOfb23WAmZkkdyV5zVrrH2bmxiT3zMz71lr/vev4AI+01e3hSvKss/9+ZpL/SPLNjcYG+Ladd1prrTUzv5zkfTPzP0muSfL6tda3dl4dwHl23mnNzF6SP8yZUL0wya1J/nxmnnvedadm5vDc5/Tp07tODVyBtrg9fEWSF6y1PpYka627kxwm+fFHXrTWun2tdXDuc/LkyQ2mBq40W0TrS0mum5kfSZKZuSnJi5P8ywZjAzzKFs+0vjozv5nkL2fm4ZwJ4e+ste7feXUA55m11pFMfHBwsA4PD49kbuBYm4ud9EY8UEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAFdECqogWUEW0gCqiBVTZJFozc/XM/MnMfG5mPjszd20xLsD59jYa54+SrCQvXWutmbl2o3EBHmXnaM3M05P8epKDtdZKkrXWV3YdF+BCtrg9fHGS/0zytpn5+5n5m5m5dYNxAb7LFtHaS/LCJP+01npVkt9L8hcz8/xHXjQzp2bm8Nzn9OnTG0wNXGnm7B3dDz7AzHOTfDXJU9ZaD509dneSP1hr/dX3+t7BwcE6PDzcaW7gCWkudnLnndZa69+T/HWSn0uSmXlRkhcl+eddxwY431a/PfytJH82M29P8nCS29Za/7bR2ADftkm01lqfT/KzW4wFcDHeiAeqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQZdNozcybZ2bNzC9uOS7AOZtFa2ZuTPIbST6x1ZgA59skWjPzpCTvSvK7Sb65xZgAF7LVTutUkr9da31yo/EALmhv1wFm5keTvCHJzzzGdadyJm5Jkv39/V2nBq5AW+y0fjrJjUk+NzNfSPJTSe6cmd9+5EVrrdvXWgfnPidPntxgauBKM2utbQec+WiSP15rvf9i1x0cHKzDw8NN5waeEOZiJ72nBVTZ+ZnW+dZar9l6TIBz7LSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoIpoAVVEC6giWkAV0QKqiBZQRbSAKqIFVBEtoMrO0ZqZEzPz/pm5d2Y+MzMfnpmbtlgcwPm22mndmeRla61bknwgybs2GhfgUXaO1lrrgbXWB9da6+yhTyS5cddxAS7kcjzTekvO7LYANre35WAz87YkNyW59QLnTiU5de7n/f39LacGrhDznbu6HQeaeWuSX0ny2rXW1x/r+oODg3V4eLjJ3MATylzs5CY7rbO7qDfmEoMF8IPaOVozc5DkHUk+n+QjM5Mk31xr/eSuYwOcb+dorbUO8xjbOYCteCMeqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gimgBVUQLqCJaQBXRAqqIFlBFtIAqogVUES2gypFF66G18uBDDx/V9ECpvaOa+P++9VD+9KP/mh96xtW5dv9EXrD/1Fy7fyLPPLGXmTmqZQHH3JFFK0keenjlK994IF/5xgP5dL6eJLn52mfkdT923VEuCzjGjt0zrWc//SlHvQTgGDt20bpu/6lHvQTgGDtW0ZpJnr9/9VEvAzjGjlW0nvP0p+TqvauOehnAMXasonVwzdOOegnAMXesovXC54gWcHHHJlonnnxVbni2aAEXd2yidcvBfvauOjbLAY6pTSoxMy+ZmY/PzL0zc/fMvPz7+f4zTuzllTdes8VSgCe4rbY2dyS5c6310iRvT/LuS/3i1U9+Un7hlhf4rSFwSXaO1sw8L8mrktx19tB7k1w/Mzc91nd/+Jqn5ld/4oY875kndl0GcIXYYqd1fZIvr7UeTJK11kpyf5IbLvalq/euyi+98iDPepo/2wEu3eP2B9MzcyrJqUcc+trMPP/xmh94YpgzG6MdBjhze3hfkmevtR6cM/+vzJeTvHqtdd8GawT4tp1vD9daX0vyqSRvOnvoDUkOBQu4HHbeaSXJzLwsZ35j+Jwk/5XkzWutz+48MMB5NokWwOPFK+hAFdECqogWUEW0gCqiBVQRLaCKaAFVRAuoIlpAlf8HIZPkQwj7cWkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 340x620 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overlayGraph(\"../data/overhang/Overhang (vertical + horizontal).mp4\", h5_file_name, 'graphvid.mp4', graphFunc, 45, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optional-domain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 340x620 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import math\n",
    "\n",
    "# playback speed = out_fps/30 * speed_up   \n",
    "# speed_up is positive int, e.g. 2 means skip every 2nd frame, 3 skip every 3rd frame\n",
    "def overlayGraph(videofile, outfile, graphFunc, out_fps, speed_up):\n",
    "    cap = cv2.VideoCapture(videofile)\n",
    "    width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    writer= cv2.VideoWriter(outfile, cv2.VideoWriter_fourcc(*'MP4V'), out_fps, (width,height))    \n",
    "\n",
    "    \"\"\" Set figure size, so it's not bigger than video \"\"\"\n",
    "    figure(num=None, figsize=((width - 20)/80, (height - 20)/80), dpi=80)\n",
    "    i = 0 # count which frame we are on\n",
    "    while True:\n",
    "        if not (i % speed_up == 0):\n",
    "            cap.read()\n",
    "            i+=1\n",
    "            continue\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        time = i / 30;\n",
    "        new_frame = graphFunc(time, frame)\n",
    "\n",
    "        writer.write(new_frame)\n",
    "        cv2.imshow('frame', new_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "            \n",
    "        i+=1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "h5_file_name = '../data/overhang/bae8f52c-407e-5f89-a8e3-61fcca51ee0a.h5'\n",
    "f = h5py.File(h5_file_name, 'r')\n",
    "height_profile = f['climbs/0/height_profile']\n",
    "max_height = max(height_profile)\n",
    "len_height = len(height_profile)\n",
    "def graphFunc(time, frame):\n",
    "    if time > len_height:\n",
    "        return True\n",
    "    plt.clf()\n",
    "    # for '/climbs/0/height_profile' we are sampling at 10Hz, i.e. every 0.1s\n",
    "    ind = min(math.floor(time/0.1), len_height) # stay in bounds\n",
    "    plt.plot(height_profile[:math.floor(time/0.1)], linewidth=7.0, alpha=0.5)\n",
    "    plt.ylim(0,max_height)\n",
    "    plt.xlim(0,len_height)\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    \n",
    "    plt.savefig('plot.png', transparent=True)\n",
    "\n",
    "    # imread_unchange reads plot.png with 4 channels, i.e. including alpha channel which\n",
    "    # describes the transparancy\n",
    "    overlay = cv2.imread('plot.png', cv2.IMREAD_UNCHANGED)\n",
    "    new_frame = frame\n",
    "\n",
    "    y_offset = x_offset = 5\n",
    "    y1, y2 = y_offset, y_offset + overlay.shape[0]\n",
    "    x1, x2 = x_offset, x_offset + overlay.shape[1]\n",
    "    alpha_o = overlay[:, :, 3] / 255.0\n",
    "    alpha_n = 1.0 - alpha_o\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        new_frame[y1:y2, x1:x2, c] = (alpha_o * overlay[:, :, c] +\n",
    "                                  alpha_n * new_frame[y1:y2, x1:x2, c])\n",
    "    \n",
    "    return new_frame\n",
    "\n",
    "overlayGraph(\"../data/overhang/Overhang (vertical + horizontal).mp4\", 'graphvid.mp4', graphFunc, 45, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-albania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-literacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-fellow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-sleep",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-fabric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-virus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-chapel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-warrior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-newman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "middle-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_df = pd.read_csv(\"../data/overhang/bae8f52c-407e-5f89-a8e3-61fcca51ee0a_moves.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand</th>\n",
       "      <th>climb_index</th>\n",
       "      <th>move_index</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>climb</th>\n",
       "      <th>on_hold</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-25 13:45:57.460000038+00:00</td>\n",
       "      <td>2021-02-25 13:45:58.559999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-25 13:46:01.960000038+00:00</td>\n",
       "      <td>2021-02-25 13:46:02.960000038+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-25 13:46:04.559999943+00:00</td>\n",
       "      <td>2021-02-25 13:46:05.859999895+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-25 13:46:06.559999943+00:00</td>\n",
       "      <td>2021-02-25 13:46:07.559999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-25 13:46:08.660000086+00:00</td>\n",
       "      <td>2021-02-25 13:46:09.559999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hand  climb_index  move_index                           start_time  \\\n",
       "0   left            0           0  2021-02-25 13:45:57.460000038+00:00   \n",
       "1  right            0           0  2021-02-25 13:46:01.960000038+00:00   \n",
       "2   left            0           1  2021-02-25 13:46:04.559999943+00:00   \n",
       "3  right            0           1  2021-02-25 13:46:06.559999943+00:00   \n",
       "4   left            0           2  2021-02-25 13:46:08.660000086+00:00   \n",
       "\n",
       "                              end_time  climb  on_hold  duration  \n",
       "0  2021-02-25 13:45:58.559999943+00:00      0     0.44       1.1  \n",
       "1  2021-02-25 13:46:02.960000038+00:00      0     4.94       1.0  \n",
       "2  2021-02-25 13:46:05.859999895+00:00      0     6.00       1.3  \n",
       "3  2021-02-25 13:46:07.559999943+00:00      0     3.60       1.0  \n",
       "4  2021-02-25 13:46:09.559999943+00:00      0     2.80       0.9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raising-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_df[['start_time', 'end_time']] = moves_df[['start_time', 'end_time']].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tender-distance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.99390600005078\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"../data/overhang/Overhang (vertical + horizontal).mp4\")\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "\n",
    "fps = cap.get(cv2.cv2.CAP_PROP_FPS)\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thick-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_frame(end_time):\n",
    "    t_step = end_time.replace(tzinfo=None)  - moves_df.start_time[0].replace(tzinfo=None) \n",
    "    frame_number = t_step.total_seconds() * fps\n",
    "    return frame_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "integrated-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_df['frame_number'] = moves_df['end_time'].apply(time_to_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automated-saturday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand</th>\n",
       "      <th>climb_index</th>\n",
       "      <th>move_index</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>climb</th>\n",
       "      <th>on_hold</th>\n",
       "      <th>duration</th>\n",
       "      <th>frame_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-25 13:45:57.460000038+00:00</td>\n",
       "      <td>2021-02-25 13:45:58.559999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.1</td>\n",
       "      <td>32.993267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-25 13:46:01.960000038+00:00</td>\n",
       "      <td>2021-02-25 13:46:02.960000038+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.966483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-25 13:46:04.559999943+00:00</td>\n",
       "      <td>2021-02-25 13:46:05.859999895+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>251.948780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-25 13:46:06.559999943+00:00</td>\n",
       "      <td>2021-02-25 13:46:07.559999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>302.938421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-25 13:46:08.660000086+00:00</td>\n",
       "      <td>2021-02-25 13:46:09.559999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.9</td>\n",
       "      <td>362.926233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-25 13:46:10.059999943+00:00</td>\n",
       "      <td>2021-02-25 13:46:11.059999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>407.917092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-02-25 13:46:13.759999990+00:00</td>\n",
       "      <td>2021-02-25 13:46:14.960000038+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.2</td>\n",
       "      <td>524.893355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-02-25 13:46:14.160000086+00:00</td>\n",
       "      <td>2021-02-25 13:46:15.859999895+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.7</td>\n",
       "      <td>551.887840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-02-25 13:46:16.259999990+00:00</td>\n",
       "      <td>2021-02-25 13:46:17.460000038+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.2</td>\n",
       "      <td>599.878120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-02-25 13:46:19.759999990+00:00</td>\n",
       "      <td>2021-02-25 13:46:21.059999943+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.3</td>\n",
       "      <td>707.856152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hand  climb_index  move_index                          start_time  \\\n",
       "0   left            0           0 2021-02-25 13:45:57.460000038+00:00   \n",
       "1  right            0           0 2021-02-25 13:46:01.960000038+00:00   \n",
       "2   left            0           1 2021-02-25 13:46:04.559999943+00:00   \n",
       "3  right            0           1 2021-02-25 13:46:06.559999943+00:00   \n",
       "4   left            0           2 2021-02-25 13:46:08.660000086+00:00   \n",
       "5  right            0           2 2021-02-25 13:46:10.059999943+00:00   \n",
       "6   left            0           3 2021-02-25 13:46:13.759999990+00:00   \n",
       "7  right            0           3 2021-02-25 13:46:14.160000086+00:00   \n",
       "8  right            0           4 2021-02-25 13:46:16.259999990+00:00   \n",
       "9   left            0           4 2021-02-25 13:46:19.759999990+00:00   \n",
       "\n",
       "                             end_time  climb  on_hold  duration  frame_number  \n",
       "0 2021-02-25 13:45:58.559999943+00:00      0     0.44       1.1     32.993267  \n",
       "1 2021-02-25 13:46:02.960000038+00:00      0     4.94       1.0    164.966483  \n",
       "2 2021-02-25 13:46:05.859999895+00:00      0     6.00       1.3    251.948780  \n",
       "3 2021-02-25 13:46:07.559999943+00:00      0     3.60       1.0    302.938421  \n",
       "4 2021-02-25 13:46:09.559999943+00:00      0     2.80       0.9    362.926233  \n",
       "5 2021-02-25 13:46:11.059999943+00:00      0     2.50       1.0    407.917092  \n",
       "6 2021-02-25 13:46:14.960000038+00:00      0     4.20       1.2    524.893355  \n",
       "7 2021-02-25 13:46:15.859999895+00:00      0     3.10       1.7    551.887840  \n",
       "8 2021-02-25 13:46:17.460000038+00:00      0     0.40       1.2    599.878120  \n",
       "9 2021-02-25 13:46:21.059999943+00:00      0     4.80       1.3    707.856152  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-printing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "artistic-drawing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-02-25 13:45:57.460000038')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df.start_time[0].replace(tzinfo=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flexible-september",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2021-02-25T13:49:59.259999990')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df.end_time.values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "preceding-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.099999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = moves_df.end_time.values[0] - moves_df.start_time[0].replace(tzinfo=None)\n",
    "t.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scheduled-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_counter = 1\n",
    "query_df = moves_df[moves_df['frame_number'] <= frame_counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "warming-recipe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-shaft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effective-demand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.99390600005078\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"../data/overhang/Overhang (vertical + horizontal).mp4\")\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "\n",
    "fps = cap.get(cv2.cv2.CAP_PROP_FPS)\n",
    "print(fps)\n",
    "\n",
    "# We need to set resolutions.\n",
    "# so, convert them from float to integer.\n",
    "width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "# Below VideoWriter object will create \n",
    "# a frame of above defined The output  \n",
    "# is stored in 'filename.avi' file. \n",
    "result= cv2.VideoWriter('moves_tracker2.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 30, (width,height))\n",
    "\n",
    "frame_counter = 0\n",
    "# Read the video\n",
    "while(cap.isOpened()):\n",
    "    # Subtract current frame from the previous \n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    canny_high = cv2.Canny(gray, 250, 500)\n",
    "    _, thresh = cv2.threshold(canny_high, 20, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    dilated = cv2.dilate(thresh, None, iterations=10)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        \n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "            \n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_4)\n",
    "    \n",
    "    query_df = moves_df[moves_df['frame_number'] <= frame_counter]\n",
    "    if query_df.shape[0] != 0:\n",
    "        cv2.putText(frame1, \"Total Moves {}\".format(query_df.move_index.values[-1]), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    \n",
    "    # Stacking the images to print them together\n",
    "    # For comparison\n",
    "    #images = np.hstack((gray, dilated1, dilated2))\n",
    "    result.write(frame1)\n",
    "    cv2.imshow('frame',frame1)\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "    frame_counter += 1\n",
    "    \n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "result.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-bottle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-subscriber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-riverside",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-naples",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nutritional-leadership",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-ms668fyv/opencv/modules/core/src/arithm.cpp:666: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ab3cff291bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Subtract current frame from the previous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-ms668fyv/opencv/modules/core/src/arithm.cpp:666: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"test.mp4\")\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "\n",
    "# We need to set resolutions. \n",
    "# so, convert them from float to integer. \n",
    "frame_width = int(cap.get(3)) \n",
    "frame_height = int(cap.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "   \n",
    "# Below VideoWriter object will create \n",
    "# a frame of above defined The output  \n",
    "# is stored in 'filename.avi' file. \n",
    "result = cv2.VideoWriter('filename.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 20.0, (640,480))\n",
    "\n",
    "# Read the video\n",
    "while(cap.isOpened()):\n",
    "    # Subtract current frame from the previous \n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "    canny = cv2.Canny(gray, 20, 30)\n",
    "    canny_high = cv2.Canny(gray, 250, 500)\n",
    "    \n",
    "    _, thresh1 = cv2.threshold(canny, 20, 255, cv2.THRESH_BINARY)\n",
    "    _, thresh2 = cv2.threshold(canny_high, 20, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    dilated1 = cv2.dilate(thresh1, None, iterations=3)\n",
    "    dilated2 = cv2.dilate(thresh2, None, iterations=10)\n",
    "    \n",
    "    contours1, _ = cv2.findContours(dilated1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours2, _ = cv2.findContours(dilated2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours2:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        \n",
    "        if cv2.contourArea(contour) < 700:\n",
    "            continue\n",
    "            \n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "    \n",
    "    \n",
    "    # Stacking the images to print them together\n",
    "    # For comparison\n",
    "    #images = np.hstack((gray, dilated1, dilated2))\n",
    "    result.write(frame1)\n",
    "    cv2.imshow('frame',frame1)\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "result.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"test.mp4\")\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        \n",
    "        if cv2.contourArea(contour) < 700:\n",
    "            continue\n",
    "            \n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        \n",
    "    \n",
    "    #cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('feed',frame1)\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if cv2.waitKey(40) == 27:\n",
    "        break\n",
    "        \n",
    "    if cv2.getWindowProperty('frame', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-fifty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "local-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 340x620 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import math\n",
    "# playback speed = out_fps/30 * speed_up   \n",
    "# speed_up is positive int, e.g. 2 means skip every 2nd frame, 3 skip every 3rd frame\n",
    "def overlayGraph(videofile, outfile, graphFunc, out_fps, speed_up):\n",
    "    cap = cv2.VideoCapture(videofile)\n",
    "    width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    writer= cv2.VideoWriter(outfile, cv2.VideoWriter_fourcc(*'MP4V'), out_fps, (width,height))    \n",
    "    \"\"\" Set figure size, so it's not bigger than video \"\"\"\n",
    "    figure(num=None, figsize=((width - 20)/80, (height - 20)/80), dpi=80)\n",
    "    i = 0 # count which frame we are on\n",
    "    while True:\n",
    "        if not (i % speed_up == 0):\n",
    "            cap.read()\n",
    "            i+=1\n",
    "            continue\n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        time = i / 30;\n",
    "        new_frame = graphFunc(time, frame)\n",
    "        writer.write(new_frame)\n",
    "        cv2.imshow('frame', new_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "            \n",
    "        i+=1\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "h5_file_name = '../data/overhang/bae8f52c-407e-5f89-a8e3-61fcca51ee0a.h5'\n",
    "f = h5py.File(h5_file_name, 'r')\n",
    "height_profile = f['climbs/0/height_profile']\n",
    "max_height = max(height_profile)\n",
    "len_height = len(height_profile)\n",
    "def graphFunc(time, frame):\n",
    "    if time > len_height:\n",
    "        return True\n",
    "    plt.clf()\n",
    "    # for '/climbs/0/height_profile' we are sampling at 10Hz, i.e. every 0.1s\n",
    "    ind = min(math.floor(time/0.1), len_height) # stay in bounds\n",
    "    plt.plot(height_profile[:math.floor(time/0.1)], linewidth=7.0, alpha=0.5)\n",
    "    plt.ylim(0,max_height)\n",
    "    plt.xlim(0,len_height)\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    \n",
    "    plt.savefig('plot.png', transparent=True)\n",
    "    # imread_unchange reads plot.png with 4 channels, i.e. including alpha channel which\n",
    "    # describes the transparancy\n",
    "    overlay = cv2.imread('plot.png', cv2.IMREAD_UNCHANGED)\n",
    "    new_frame = frame\n",
    "    y_offset = x_offset = 5\n",
    "    y1, y2 = y_offset, y_offset + overlay.shape[0]\n",
    "    x1, x2 = x_offset, x_offset + overlay.shape[1]\n",
    "    alpha_o = overlay[:, :, 3] / 255.0\n",
    "    alpha_n = 1.0 - alpha_o\n",
    "    for c in range(0, 3):\n",
    "        new_frame[y1:y2, x1:x2, c] = (alpha_o * overlay[:, :, c] +\n",
    "                                  alpha_n * new_frame[y1:y2, x1:x2, c])\n",
    "    \n",
    "    return new_frame\n",
    "overlayGraph(\"../data/overhang/Overhang (vertical + horizontal).mp4\", 'graphvid.mp4', graphFunc, 45, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-hotel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starthack",
   "language": "python",
   "name": "starthack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
